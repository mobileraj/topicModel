library(tm)
setwd("/home/raj/projects/topicModels/topics")
fi <- list.files(getwd(),pattern="*.txt")
foo <- lapply(fi,readLines)
docs<-Corpus(VectorSource(foo))
docs<-tm_map(docs,content_transformer(tolower))
toSpace<- content_transformer(function(x,pattern) { return (gsub(pattern," ",x))})
docs<-tm_map(docs,toSpace,"-")
docs<-tm_map(docs,toSpace,"'")
docs<-tm_map(docs,toSpace,".")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords('english'))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs,stemDocument)
myStopwords <- c('can', 'now','will','berkshire','say','one','way','use','berkshire','hathaway','berkshires','also','howev','tell','business','from','the','that','and','for','have','berkshir','year','years','company','last','however','many','every','made','next')
docs <- tm_map(docs, removeWords, myStopwords)
dtm <- DocumentTermMatrix(docs)
rownames(dtm) <- fi
freq <- colSums(as.matrix(dtm))
length(freq)
ord <- order(freq,decreasing=TRUE)
freq[ord]
write.csv(freq[ord],'word_freq.csv')

library(topicmodels)
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
k <- 5

rowTotals <- apply(dtm , 1, sum) #Find the sum of words in each Document
dtm   <- dtm[rowTotals> 0, ]

ldaOut <-LDA(dtm,k, method='Gibbs', control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
ldaOut.topics <- as.matrix(topics(ldaOut))
write.csv(ldaOut.topics,file=paste('LDAGibbs',k,'DocsToTopics.csv'))
ldaOut.terms <- as.matrix(terms(ldaOut,6))
write.csv(ldaOut.terms,file=paste('LDAGibbs',k,'TopicsToTerms.csv'))
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste('LDAGibbs',k,'TopicProbabilities.csv'))
